{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c9660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214a8f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Responda a seguinte pergunta do usuário:\n",
    "    {pergunta}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f6c5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Responda a seguinte pergunta do usuário:\n",
      "    O que é um SaaS ?\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(pergunta=\"O que é um SaaS ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07e9f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Responda a seguinte pergunta do usuário em até {n_palavras} palavras:\n",
    "    {pergunta}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270b35bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Responda a seguinte pergunta do usuário em até 15 palavras:\n",
      "    O que é um SaaS ?\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(pergunta=\"O que é um SaaS ?\", n_palavras = 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c278a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Responda a seguinte pergunta do usuário em até {n_palavras} palavras:\n",
    "    {pergunta}\n",
    "    \"\"\",\n",
    "    partial_variables={'n_palavras': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef83318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Responda a seguinte pergunta do usuário em até 10 palavras:\n",
      "    O que é LangChain ?\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(pergunta=\"O que é LangChain ?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2032ded1",
   "metadata": {},
   "source": [
    "### Utilizando multiplos prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82b800c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template_word_count = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Responda a pergunta em até {n_palavras} palavras.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "template_line_count = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Responda a pergunta em até {n_linhas} linhas.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "template_idioma = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Responda a pergunta em {idioma}.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "template_final = (template_word_count + template_line_count + template_idioma + \n",
    "                  \"Responda a pergunta seguindo as instruções acima. Pergunta: {pergunta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d65009d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'idioma'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'n_linhas'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'n_palavras'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pergunta'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\n    Responda a pergunta em até {n_palavras} palavras.\\n    \\n    Responda a pergunta em até </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{n_linhas} linhas.\\n    \\n    Responda a pergunta em {idioma}.\\n    Responda a pergunta seguindo as instruções </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">acima. Pergunta: {pergunta}'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'idioma'\u001b[0m, \u001b[32m'n_linhas'\u001b[0m, \u001b[32m'n_palavras'\u001b[0m, \u001b[32m'pergunta'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mtemplate\u001b[0m=\u001b[32m'\\n    Responda a pergunta em até \u001b[0m\u001b[32m{\u001b[0m\u001b[32mn_palavras\u001b[0m\u001b[32m}\u001b[0m\u001b[32m palavras.\\n    \\n    Responda a pergunta em até \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32mn_linhas\u001b[0m\u001b[32m}\u001b[0m\u001b[32m linhas.\\n    \\n    Responda a pergunta em \u001b[0m\u001b[32m{\u001b[0m\u001b[32midioma\u001b[0m\u001b[32m}\u001b[0m\u001b[32m.\\n    Responda a pergunta seguindo as instruções \u001b[0m\n",
       "\u001b[32macima. Pergunta: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mpergunta\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "print(template_final, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd01930a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nO Sol é a estrela central do sistema solar, responsável por fornecer luz e calor para a Terra. '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_final = template_final.format(\n",
    "    n_palavras=15,\n",
    "    idioma=\"inglês\",\n",
    "    n_linhas=1,\n",
    "    pergunta=\"O que é o Sol?\"\n",
    ")\n",
    "\n",
    "llm.invoke(prompt_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a7bb958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "    Responda a pergunta em até <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> palavras.\n",
       "    \n",
       "    Responda a pergunta em até <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> linhas.\n",
       "    \n",
       "    Responda a pergunta em inglês.\n",
       "    Responda a pergunta seguindo as instruções acima. Pergunta: O que é o Sol?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "    Responda a pergunta em até \u001b[1;36m15\u001b[0m palavras.\n",
       "    \n",
       "    Responda a pergunta em até \u001b[1;36m1\u001b[0m linhas.\n",
       "    \n",
       "    Responda a pergunta em inglês.\n",
       "    Responda a pergunta seguindo as instruções acima. Pergunta: O que é o Sol?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(prompt_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa5139c",
   "metadata": {},
   "source": [
    "### Templates para Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83b416bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Essa é minha dúvida: Quem é você?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_template(\"Essa é minha dúvida: {duvida}\")\n",
    "chat_template.format_messages(duvida=\"Quem é você?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a887d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Você é um assistente irônico e se chama {nome_assistente}\"),\n",
    "        (\"human\", \"Olá, como vai?\"),\n",
    "        (\"ai\", \"Estou bem, como posso lhe ajudar?\"),\n",
    "        (\"human\", \"{pergunta}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3805d230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['nome_assistente', 'pergunta'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['nome_assistente'], input_types={}, partial_variables={}, template='Você é um assistente irônico e se chama {nome_assistente}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Olá, como vai?'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Estou bem, como posso lhe ajudar?'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pergunta'], input_types={}, partial_variables={}, template='{pergunta}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7107371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Você é um assistente irônico e se chama BotX', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Olá, como vai?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Estou bem, como posso lhe ajudar?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Qual é o seu nome?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template.format_messages(\n",
    "    nome_assistente=\"BotX\",\n",
    "    pergunta=\"Qual é o seu nome?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3c3774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb29df98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Meu nome é BotX. Como posso te ajudar hoje?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 57, 'total_tokens': 72, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BjkLgLjGh7VdSri7MAgJHoGNv52Px', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f60b0655-fa97-4598-bb58-1a7b17bd5d81-0', usage_metadata={'input_tokens': 57, 'output_tokens': 15, 'total_tokens': 72, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(chat_template.format_messages(\n",
    "    nome_assistente=\"BotX\",\n",
    "    pergunta=\"Qual é o seu nome?\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e042a8f0",
   "metadata": {},
   "source": [
    "### Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "426f3d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplos = [\n",
    "    {\"pergunta\": \"Qual é a maior montanha do mundo, o Monte Everest ou o K2?\", \n",
    "     \"resposta\": \n",
    "     \"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Qual é a altura do Monte Everest? \n",
    "Resposta intermediária: O Monte Everest tem 8.848 metros de altura. \n",
    "Pergunta de acompanhamento: Qual é a altura do K2? \n",
    "Resposta intermediária: O K2 tem 8.611 metros de altura. \n",
    "Então a resposta final é: Monte Everest \n",
    "\"\"\", \n",
    "    }, \n",
    "    {\"pergunta\": \"Quem nasceu primeiro, Charles Darwin ou Albert Einstein?\", \n",
    "     \"resposta\": \n",
    "     \"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quando nasceu Charles Darwin? \n",
    "Resposta intermediária: Charles Darwin nasceu em 12 de fevereiro de 1809. \n",
    "Pergunta de acompanhamento: Quando nasceu Albert Einstein? \n",
    "Resposta intermediária: Albert Einstein nasceu em 14 de março de 1879. \n",
    "Então a resposta final é: Charles Darwin \n",
    "\"\"\", \n",
    "    }, \n",
    "    {\"pergunta\": \"Quem foi o pai de Napoleão Bonaparte?\",\n",
    "     \"resposta\": \n",
    "     \"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quem foi Napoleão Bonaparte? \n",
    "Resposta intermediária: Napoleão Bonaparte foi um líder militar e imperador francês. \n",
    "Pergunta de acompanhamento: Quem foi o pai de Napoleão Bonaparte? \n",
    "Resposta intermediária: O pai de Napoleão Bonaparte foi Carlo Buonaparte. \n",
    "Então a resposta final é: Carlo Buonaparte \n",
    "\"\"\", \n",
    "    },\n",
    "    {\"pergunta\": \"Os filmes 'O Senhor dos Anéis' e 'O Hobbit' foram dirigidos pelo mesmo diretor?\", \n",
    "     \"resposta\": \n",
    "     \"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quem dirigiu 'O Senhor dos Anéis'? \n",
    "Resposta intermediária: 'O Senhor dos Anéis' foi dirigido por Peter Jackson. \n",
    "Pergunta de acompanhamento: Quem dirigiu 'O Hobbit'? \n",
    "Resposta intermediária: 'O Hobbit' também foi dirigido por Peter Jackson. \n",
    "Então a resposta final é: Sim \n",
    "\"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "819bbcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pergunta Qual é a maior montanha do mundo, o Monte Everest ou o K2?\\nSão necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Qual é a altura do Monte Everest? \\nResposta intermediária: O Monte Everest tem 8.848 metros de altura. \\nPergunta de acompanhamento: Qual é a altura do K2? \\nResposta intermediária: O K2 tem 8.611 metros de altura. \\nEntão a resposta final é: Monte Everest \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"pergunta\", \"resposta\"],\n",
    "    template=\"Pergunta {pergunta}\\n{resposta}\"\n",
    ")\n",
    "\n",
    "example_prompt.format(**exemplos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca6ea8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=exemplos,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Pergunta: {input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cf7a22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pergunta Qual é a maior montanha do mundo, o Monte Everest ou o K2?\n",
       "São necessárias perguntas de acompanhamento aqui: Sim. \n",
       "Pergunta de acompanhamento: Qual é a altura do Monte Everest? \n",
       "Resposta intermediária: O Monte Everest tem <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.848</span> metros de altura. \n",
       "Pergunta de acompanhamento: Qual é a altura do K2? \n",
       "Resposta intermediária: O K2 tem <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.611</span> metros de altura. \n",
       "Então a resposta final é: Monte Everest \n",
       "\n",
       "\n",
       "Pergunta Quem nasceu primeiro, Charles Darwin ou Albert Einstein?\n",
       "São necessárias perguntas de acompanhamento aqui: Sim. \n",
       "Pergunta de acompanhamento: Quando nasceu Charles Darwin? \n",
       "Resposta intermediária: Charles Darwin nasceu em <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> de fevereiro de <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1809</span>. \n",
       "Pergunta de acompanhamento: Quando nasceu Albert Einstein? \n",
       "Resposta intermediária: Albert Einstein nasceu em <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> de março de <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1879</span>. \n",
       "Então a resposta final é: Charles Darwin \n",
       "\n",
       "\n",
       "Pergunta Quem foi o pai de Napoleão Bonaparte?\n",
       "São necessárias perguntas de acompanhamento aqui: Sim. \n",
       "Pergunta de acompanhamento: Quem foi Napoleão Bonaparte? \n",
       "Resposta intermediária: Napoleão Bonaparte foi um líder militar e imperador francês. \n",
       "Pergunta de acompanhamento: Quem foi o pai de Napoleão Bonaparte? \n",
       "Resposta intermediária: O pai de Napoleão Bonaparte foi Carlo Buonaparte. \n",
       "Então a resposta final é: Carlo Buonaparte \n",
       "\n",
       "\n",
       "Pergunta Os filmes <span style=\"color: #008000; text-decoration-color: #008000\">'O Senhor dos Anéis'</span> e <span style=\"color: #008000; text-decoration-color: #008000\">'O Hobbit'</span> foram dirigidos pelo mesmo diretor?\n",
       "São necessárias perguntas de acompanhamento aqui: Sim. \n",
       "Pergunta de acompanhamento: Quem dirigiu <span style=\"color: #008000; text-decoration-color: #008000\">'O Senhor dos Anéis'</span>? \n",
       "Resposta intermediária: <span style=\"color: #008000; text-decoration-color: #008000\">'O Senhor dos Anéis'</span> foi dirigido por Peter Jackson. \n",
       "Pergunta de acompanhamento: Quem dirigiu <span style=\"color: #008000; text-decoration-color: #008000\">'O Hobbit'</span>? \n",
       "Resposta intermediária: <span style=\"color: #008000; text-decoration-color: #008000\">'O Hobbit'</span> também foi dirigido por Peter Jackson. \n",
       "Então a resposta final é: Sim \n",
       "\n",
       "\n",
       "Pergunta: Quem é melhor, Messi ou Cristiano Ronaldo?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pergunta Qual é a maior montanha do mundo, o Monte Everest ou o K2?\n",
       "São necessárias perguntas de acompanhamento aqui: Sim. \n",
       "Pergunta de acompanhamento: Qual é a altura do Monte Everest? \n",
       "Resposta intermediária: O Monte Everest tem \u001b[1;36m8.848\u001b[0m metros de altura. \n",
       "Pergunta de acompanhamento: Qual é a altura do K2? \n",
       "Resposta intermediária: O K2 tem \u001b[1;36m8.611\u001b[0m metros de altura. \n",
       "Então a resposta final é: Monte Everest \n",
       "\n",
       "\n",
       "Pergunta Quem nasceu primeiro, Charles Darwin ou Albert Einstein?\n",
       "São necessárias perguntas de acompanhamento aqui: Sim. \n",
       "Pergunta de acompanhamento: Quando nasceu Charles Darwin? \n",
       "Resposta intermediária: Charles Darwin nasceu em \u001b[1;36m12\u001b[0m de fevereiro de \u001b[1;36m1809\u001b[0m. \n",
       "Pergunta de acompanhamento: Quando nasceu Albert Einstein? \n",
       "Resposta intermediária: Albert Einstein nasceu em \u001b[1;36m14\u001b[0m de março de \u001b[1;36m1879\u001b[0m. \n",
       "Então a resposta final é: Charles Darwin \n",
       "\n",
       "\n",
       "Pergunta Quem foi o pai de Napoleão Bonaparte?\n",
       "São necessárias perguntas de acompanhamento aqui: Sim. \n",
       "Pergunta de acompanhamento: Quem foi Napoleão Bonaparte? \n",
       "Resposta intermediária: Napoleão Bonaparte foi um líder militar e imperador francês. \n",
       "Pergunta de acompanhamento: Quem foi o pai de Napoleão Bonaparte? \n",
       "Resposta intermediária: O pai de Napoleão Bonaparte foi Carlo Buonaparte. \n",
       "Então a resposta final é: Carlo Buonaparte \n",
       "\n",
       "\n",
       "Pergunta Os filmes \u001b[32m'O Senhor dos Anéis'\u001b[0m e \u001b[32m'O Hobbit'\u001b[0m foram dirigidos pelo mesmo diretor?\n",
       "São necessárias perguntas de acompanhamento aqui: Sim. \n",
       "Pergunta de acompanhamento: Quem dirigiu \u001b[32m'O Senhor dos Anéis'\u001b[0m? \n",
       "Resposta intermediária: \u001b[32m'O Senhor dos Anéis'\u001b[0m foi dirigido por Peter Jackson. \n",
       "Pergunta de acompanhamento: Quem dirigiu \u001b[32m'O Hobbit'\u001b[0m? \n",
       "Resposta intermediária: \u001b[32m'O Hobbit'\u001b[0m também foi dirigido por Peter Jackson. \n",
       "Então a resposta final é: Sim \n",
       "\n",
       "\n",
       "Pergunta: Quem é melhor, Messi ou Cristiano Ronaldo?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(prompt.format(input=\"Quem é melhor, Messi ou Cristiano Ronaldo?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88d00f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "São necessárias perguntas de acompanhamento aqui: Sim. \n",
       "Pergunta de acompanhamento: Quantos gols Messi fez na carreira? \n",
       "Resposta intermediária: Messi fez <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">698</span> gols na carreira. \n",
       "Pergunta de acompanhamento: Quantos gols Cristiano Ronaldo fez na carreira? \n",
       "Resposta intermediária: Cristiano Ronaldo fez <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">725</span> gols na carreira. \n",
       "Então a resposta final é: Cristiano Ronaldo\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "São necessárias perguntas de acompanhamento aqui: Sim. \n",
       "Pergunta de acompanhamento: Quantos gols Messi fez na carreira? \n",
       "Resposta intermediária: Messi fez \u001b[1;36m698\u001b[0m gols na carreira. \n",
       "Pergunta de acompanhamento: Quantos gols Cristiano Ronaldo fez na carreira? \n",
       "Resposta intermediária: Cristiano Ronaldo fez \u001b[1;36m725\u001b[0m gols na carreira. \n",
       "Então a resposta final é: Cristiano Ronaldo\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(llm.invoke(prompt.format(input=\"Quem fez mais gols, Messi ou Cristiano Ronaldo?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71fbaa7",
   "metadata": {},
   "source": [
    "### Few Shot Prompting Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc4d53e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Pergunta: Qual é a maior montanha do mundo, o Monte Everest ou o K2?'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Resposta: São necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Qual é a altura do Monte Everest? \\nResposta intermediária: O Monte Everest tem 8.848 metros de altura. \\nPergunta </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">de acompanhamento: Qual é a altura do K2? \\nResposta intermediária: O K2 tem 8.611 metros de altura. \\nEntão a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">resposta final é: Monte Everest \\n'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{}</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Pergunta: Qual é a maior montanha do mundo, o Monte Everest ou o K2?'\u001b[0m,\n",
       "        \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Resposta: São necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: \u001b[0m\n",
       "\u001b[32mQual é a altura do Monte Everest? \\nResposta intermediária: O Monte Everest tem 8.848 metros de altura. \\nPergunta \u001b[0m\n",
       "\u001b[32mde acompanhamento: Qual é a altura do K2? \\nResposta intermediária: O K2 tem 8.611 metros de altura. \\nEntão a \u001b[0m\n",
       "\u001b[32mresposta final é: Monte Everest \\n'\u001b[0m,\n",
       "        \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Pergunta: {pergunta}\"),\n",
    "    (\"ai\", \"Resposta: {resposta}\")\n",
    "])\n",
    "\n",
    "print(example_prompt.format_messages(**exemplos[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb7884df",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_template = FewShotChatMessagePromptTemplate(\n",
    "    examples=exemplos,\n",
    "    example_prompt=example_prompt\n",
    ")\n",
    "\n",
    "prompt_final = ChatPromptTemplate.from_messages([\n",
    "    few_shot_template,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "prompt = prompt_final.format_messages(input=\"Quem fez mais gols, Messi ou Cristiano Ronaldo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9c55066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Essa pergunta é mais complexa do que parece, pois ambos os jogadores têm carreiras prolíficas em </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">termos de gols marcados. Para uma resposta precisa, é importante verificar os números mais recentes de gols de cada</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">jogador e considerar todas as competições em que eles participaram. Como esses números estão sempre mudando devido </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aos jogos em andamento e novas temporadas, recomenda-se consultar fontes atualizadas para obter a contagem mais </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">precisa.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'refusal'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">106</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">544</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">650</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens_details'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'accepted_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'rejected_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'cached_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-3.5-turbo-0125'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-BjkaeevQkLmvUHNDaqunwoWMp1iz1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'service_tier'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run--4adef1c6-8ede-481f-ac60-6dd35b471d40-0'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">544</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">106</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">650</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'input_token_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'audio'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'cache_read'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'output_token_details'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'audio'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m'Essa pergunta é mais complexa do que parece, pois ambos os jogadores têm carreiras prolíficas em \u001b[0m\n",
       "\u001b[32mtermos de gols marcados. Para uma resposta precisa, é importante verificar os números mais recentes de gols de cada\u001b[0m\n",
       "\u001b[32mjogador e considerar todas as competições em que eles participaram. Como esses números estão sempre mudando devido \u001b[0m\n",
       "\u001b[32maos jogos em andamento e novas temporadas, recomenda-se consultar fontes atualizadas para obter a contagem mais \u001b[0m\n",
       "\u001b[32mprecisa.'\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m106\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m544\u001b[0m,\n",
       "            \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m650\u001b[0m,\n",
       "            \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'accepted_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "                \u001b[32m'rejected_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'cached_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'gpt-3.5-turbo-0125'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'id'\u001b[0m: \u001b[32m'chatcmpl-BjkaeevQkLmvUHNDaqunwoWMp1iz1'\u001b[0m,\n",
       "        \u001b[32m'service_tier'\u001b[0m: \u001b[32m'default'\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run--4adef1c6-8ede-481f-ac60-6dd35b471d40-0'\u001b[0m,\n",
       "    \u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m544\u001b[0m,\n",
       "        \u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m106\u001b[0m,\n",
       "        \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m650\u001b[0m,\n",
       "        \u001b[32m'input_token_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'audio'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'cache_read'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'output_token_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'audio'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'reasoning'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(chat.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c469e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
