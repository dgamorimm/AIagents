{"docstore/metadata": {"ea67ed87-d68d-48b1-b9e5-f3823d6cda4a": {"doc_hash": "61f3946d3408603354d9fa936a6f0c55ff33d0bc58de601954eae0d88d63d217"}, "fe75db9f-555e-474d-ab2c-0e5cbc75d71c": {"doc_hash": "a92110178c3e19dec4e3ee1946815ad428695f4999401f64618312c0fc77e7f4"}, "83af58d3-8d28-44b3-8497-2752d144aa1b": {"doc_hash": "2086e45660865a8a01d645c4bce970793d55d632582d28bc06de7d46dbd94958"}, "db319154-9630-4daf-92b7-1853785e01b2": {"doc_hash": "22c4e5d2bb45a5b1adc23cf93a20cba356ac87aeb8c949101a6654009a844a37"}, "d014c58c-26a1-4571-bf5a-fc493d64a10b": {"doc_hash": "5738acd3b4d2585b1f155b0ae349489ab3786925691f342654e2b01b64723697"}, "57bce444-d5c7-4bc0-99eb-484872105194": {"doc_hash": "98c4f8f192ce033287b40a69b621f31fc784c8cf434494d111440c2ff31340ae"}, "0babd3ae-713f-47de-ae7a-786346100d64": {"doc_hash": "fc71f7b2119e4ab5e331ab68cf2c7bf5834c524892c5f3f6ca539b8459cc4e3a"}, "bee1c6c4-4bd6-4c35-b3cf-a6db500dda1d": {"doc_hash": "c6769bd8ef6c0a4d9a8797b6dfd1987d778300c57706b180e6d558baec21f5c2"}, "7475057c-b382-43d0-a062-1e7ad258d49a": {"doc_hash": "dc20901fb705650020bb503837780b0bd4d59ccc9eef6ba1c14d66c30b0dbee7"}, "29e5af2e-478a-4531-b603-a0b296eeeebd": {"doc_hash": "4664af0aa1d270ea0da28f2da85b363784f06d57353d5a127d5620f9899fca83", "ref_doc_id": "ea67ed87-d68d-48b1-b9e5-f3823d6cda4a"}, "c580abb9-d6ab-49ad-962d-25f975206fdb": {"doc_hash": "cbbf7765dd4877c7bd315930bfc151ec695576c9c19e057cc7196f4bf3dbb90f", "ref_doc_id": "fe75db9f-555e-474d-ab2c-0e5cbc75d71c"}, "8c63657f-9247-4f8f-92ad-92db27fb65d4": {"doc_hash": "e47c1d3e9507b137f15c10127797b9b1c3d0ea91a0ba85f2a365e3bac38af1dc", "ref_doc_id": "83af58d3-8d28-44b3-8497-2752d144aa1b"}, "79e4b060-5a0a-4329-9eff-c860970372a6": {"doc_hash": "d24ec646e7fb4f90f3be2dcebe8ffde488b9f975353b85c842fc0b7c1eccd15e", "ref_doc_id": "db319154-9630-4daf-92b7-1853785e01b2"}, "7e9e1731-5f61-422f-a604-e2e192f757d8": {"doc_hash": "12b7a37a51f43154e5b1ea884596b991334ad70056095c25625f488217653a6a", "ref_doc_id": "d014c58c-26a1-4571-bf5a-fc493d64a10b"}, "c9ee7006-4e42-44be-9de3-b24037382828": {"doc_hash": "492fd9c921de2d9dd973908be251ba2d25a62bbee402e7c167c893ee3bf61049", "ref_doc_id": "57bce444-d5c7-4bc0-99eb-484872105194"}, "5362e89b-67da-44cb-934b-492123e1e13b": {"doc_hash": "4f3e1d2cc984d03eebc78e824ef4a87a5bdcc6219e0c384c79eb8b4018ffa054", "ref_doc_id": "0babd3ae-713f-47de-ae7a-786346100d64"}, "05cdea87-9848-4b4d-ab18-edd2ad6adfdf": {"doc_hash": "920d1e82348c3b531a8f3af882d4057b8833f0f97b13c807c8a13b065f90dbf6", "ref_doc_id": "bee1c6c4-4bd6-4c35-b3cf-a6db500dda1d"}, "925a460b-d374-4cd5-ae76-43b1ca80b57f": {"doc_hash": "042d4732d5082c5242c774e3caf9ba21d466ca770f628165f7ee8767a6d42c69", "ref_doc_id": "7475057c-b382-43d0-a062-1e7ad258d49a"}}, "docstore/ref_doc_info": {"ea67ed87-d68d-48b1-b9e5-f3823d6cda4a": {"node_ids": ["29e5af2e-478a-4531-b603-a0b296eeeebd"], "metadata": {"page_label": "1", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}}, "fe75db9f-555e-474d-ab2c-0e5cbc75d71c": {"node_ids": ["c580abb9-d6ab-49ad-962d-25f975206fdb"], "metadata": {"page_label": "2", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}}, "83af58d3-8d28-44b3-8497-2752d144aa1b": {"node_ids": ["8c63657f-9247-4f8f-92ad-92db27fb65d4"], "metadata": {"page_label": "3", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}}, "db319154-9630-4daf-92b7-1853785e01b2": {"node_ids": ["79e4b060-5a0a-4329-9eff-c860970372a6"], "metadata": {"page_label": "4", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}}, "d014c58c-26a1-4571-bf5a-fc493d64a10b": {"node_ids": ["7e9e1731-5f61-422f-a604-e2e192f757d8"], "metadata": {"page_label": "5", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}}, "57bce444-d5c7-4bc0-99eb-484872105194": {"node_ids": ["c9ee7006-4e42-44be-9de3-b24037382828"], "metadata": {"page_label": "6", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}}, "0babd3ae-713f-47de-ae7a-786346100d64": {"node_ids": ["5362e89b-67da-44cb-934b-492123e1e13b"], "metadata": {"page_label": "7", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}}, "bee1c6c4-4bd6-4c35-b3cf-a6db500dda1d": {"node_ids": ["05cdea87-9848-4b4d-ab18-edd2ad6adfdf"], "metadata": {"page_label": "8", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}}, "7475057c-b382-43d0-a062-1e7ad258d49a": {"node_ids": ["925a460b-d374-4cd5-ae76-43b1ca80b57f"], "metadata": {"page_label": "9", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}}}, "docstore/data": {"29e5af2e-478a-4531-b603-a0b296eeeebd": {"__data__": {"id_": "29e5af2e-478a-4531-b603-a0b296eeeebd", "embedding": null, "metadata": {"page_label": "1", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ea67ed87-d68d-48b1-b9e5-f3823d6cda4a", "node_type": "4", "metadata": {"page_label": "1", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "hash": "61f3946d3408603354d9fa936a6f0c55ff33d0bc58de601954eae0d88d63d217", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "E-BOOK \nUm guia compacto sobre Large Language Models (LLM)", "mimetype": "text/plain", "start_char_idx": 12, "end_char_idx": 70, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c580abb9-d6ab-49ad-962d-25f975206fdb": {"__data__": {"id_": "c580abb9-d6ab-49ad-962d-25f975206fdb", "embedding": null, "metadata": {"page_label": "2", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fe75db9f-555e-474d-ab2c-0e5cbc75d71c", "node_type": "4", "metadata": {"page_label": "2", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "hash": "a92110178c3e19dec4e3ee1946815ad428695f4999401f64618312c0fc77e7f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2 \n \n  \n       PARTE  1 \nIntrodu\u00e7\u00e3o   Defini\u00e7\u00e3o de LLM (tradu\u00e7\u00e3o livre: grandes modelos de linguagem) LLMs s\u00e3o sistemas de IA desenvolvidos para processar e analisar enormes quantidades de dados de linguagem natural e, em seguida, usar essas informa\u00e7\u00f5es para gerar respostas \u00e0s solicita\u00e7\u00f5es dos usu\u00e1rios. Esses sistemas s\u00e3o treinados em grandes conjuntos de dados usando algoritmos avan\u00e7ados de machine learning para aprender os padr\u00f5es e as estruturas da linguagem humana e s\u00e3o capazes de gerar respostas em linguagem natural a uma ampla variedade de contribui\u00e7\u00f5es escritas. Os grandes modelos de linguagem est\u00e3o se tornando cada vez mais importantes em uma variedade de aplicativos, como processamento de linguagem natural, tradu\u00e7\u00e3o autom\u00e1tica, gera\u00e7\u00e3o de c\u00f3digo e texto e muito mais. Embora este guia tenha como foco os modelos de linguagem, \u00e9 fundamental compreender que eles representam apenas um elemento dentro do vasto espectro da IA generativa. Outras implementa\u00e7\u00f5es not\u00e1veis de IA generativa incluem projetos como a gera\u00e7\u00e3o de arte a partir de texto, \u00e1udio e v\u00eddeo, e certamente muitas outras novidades surgir\u00e3o em breve.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1131, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8c63657f-9247-4f8f-92ad-92db27fb65d4": {"__data__": {"id_": "8c63657f-9247-4f8f-92ad-92db27fb65d4", "embedding": null, "metadata": {"page_label": "3", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "83af58d3-8d28-44b3-8497-2752d144aa1b", "node_type": "4", "metadata": {"page_label": "3", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "hash": "2086e45660865a8a01d645c4bce970793d55d632582d28bc06de7d46dbd94958", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3 \n \n  \n      Breve hist\u00f3rico e resumo do desenvolvimento dos LLMs  D\u00e9cadas de 1950 a 1990 Foram feitas tentativas iniciais para criar regras r\u00edgidas para as linguagens e seguir passos l\u00f3gicos para realizar tarefas como traduzir frases de um idioma para outro. Embora esse m\u00e9todo funcionasse em alguns casos, estava limitado a tarefas bem definidas das quais o sistema tinha conhecimento.  D\u00e9cada de 1990 Os modelos de linguagem come\u00e7aram a evoluir para modelos estat\u00edsticos, e os padr\u00f5es lingu\u00edsticos come\u00e7aram a ser analisados, mas projetos em larga escala eram limitados pela capacidade de processamento de dados.  Anos 2000 Os avan\u00e7os em machine learning aumentaram a complexidade dos modelos de linguagem, e a ampla ado\u00e7\u00e3o da internet forneceu uma grande quantidade de dados de treinamento.  2012 Os avan\u00e7os em arquiteturas de deep learning e conjuntos de dados maiores levaram ao desenvolvimento do GPT (Transformadores Pr\u00e9-treinados Generativos). \n2018 O Google apresentou o BERT (Bidirectional Encoder Representations from Transformers), que foi um grande salto na arquitetura e abriu caminho para futuros grandes modelos de linguagem.  2020 A OpenAI lan\u00e7ou o GPT-3, que se tornou o maior modelo com 175 bilh\u00f5es de par\u00e2metros e estabeleceu um novo referencial de desempenho para tarefas relacionadas \u00e0 linguagem.  2022 O ChatGPT foi lan\u00e7ado, transformando o GPT-3 e modelos semelhantes em um servi\u00e7o amplamente acess\u00edvel aos usu\u00e1rios por meio de uma interface web, o que iniciou um aumento significativo na conscientiza\u00e7\u00e3o p\u00fablica sobre LLMs e IA generativa.  2023 Os LLMs de c\u00f3digo aberto come\u00e7am a apresentar resultados cada vez mais impressionantes, com lan\u00e7amentos como Dolly 2.0, LLaMA, Alpaca e Vicuna. O GPT-4 tamb\u00e9m \u00e9 lan\u00e7ado, estabelecendo um novo referencial tanto em tamanho de par\u00e2metros quanto em desempenho.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1829, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "79e4b060-5a0a-4329-9eff-c860970372a6": {"__data__": {"id_": "79e4b060-5a0a-4329-9eff-c860970372a6", "embedding": null, "metadata": {"page_label": "4", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "db319154-9630-4daf-92b7-1853785e01b2", "node_type": "4", "metadata": {"page_label": "4", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "hash": "22c4e5d2bb45a5b1adc23cf93a20cba356ac87aeb8c949101a6654009a844a37", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4 \n \n  \n       PARTE 2 \nCompreendendo os grandes modelos de linguagem (LLMs)    O que s\u00e3o modelos de linguagem e como eles funcionam? Os grandes modelos de linguagem s\u00e3o sistemas avan\u00e7ados de intelig\u00eancia artificial que recebem entradas e geram respostas semelhantes \u00e0s de seres humanos em forma de texto. Eles funcionam primeiro analisando enormes quantidades de dados e criando uma estrutura interna que modela os conjuntos de dados de linguagem natural nos quais foram treinados. Uma vez que essa estrutura interna tenha sido desenvolvida, os modelos podem receber entradas na forma de linguagem natural e produzir uma resposta adequada.   Se eles existem h\u00e1 tantos anos, por que s\u00f3 agora est\u00e3o ganhando destaque? Alguns avan\u00e7os recentes trouxeram grande destaque \u00e0 IA generativa e aos grandes modelos de linguagem:   AVAN\u00c7OS EM T\u00c9CNICAS  Nos \u00faltimos anos, houve avan\u00e7os significativos nas t\u00e9cnicas usadas para treinar esses modelos, resultando em grandes melhorias de desempenho. Notavelmente, um dos maiores saltos de desempenho veio da integra\u00e7\u00e3o do feedback humano diretamente no processo de treinamento. \nMAIOR ACESSIBILIDADE  O lan\u00e7amento do ChatGPT abriu as portas para qualquer pessoa com acesso \u00e0 internet interagir com um dos LLMs mais avan\u00e7ados por meio de uma interface web simples. Isso trouxe os impressionantes avan\u00e7os dos LLMs para o centro das aten\u00e7\u00f5es, uma vez que anteriormente esses modelos mais poderosos estavam dispon\u00edveis apenas para pesquisadores com recursos significativos e conhecimento t\u00e9cnico profundo.  AUMENTO DA POT\u00caNCIA COMPUTACIONAL  A disponibilidade de recursos de computa\u00e7\u00e3o mais poderosos, como unidades de processamento gr\u00e1fico (GPUs), e melhores t\u00e9cnicas de processamento de dados permitiu que os pesquisadores treinassem modelos muito maiores, melhorando o desempenho desses modelos de linguagem.  MELHORIA DOS DADOS DE TREINAMENTO \u00c0 medida que progredimos na coleta e an\u00e1lise de grandes volumes de dados, o desempenho dos modelos melhorou drasticamente. Na verdade, a Databricks demonstrou que \u00e9 poss\u00edvel obter resultados incr\u00edveis treinando um modelo relativamente pequeno com um conjunto de dados de alta qualidade com o Dolly 2.0 (e tamb\u00e9m lan\u00e7amos o conjunto de dados com o conjunto de dados databricks-dolly-15k http://databricks/databricks-dolly-15k).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2303, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7e9e1731-5f61-422f-a604-e2e192f757d8": {"__data__": {"id_": "7e9e1731-5f61-422f-a604-e2e192f757d8", "embedding": null, "metadata": {"page_label": "5", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d014c58c-26a1-4571-bf5a-fc493d64a10b", "node_type": "4", "metadata": {"page_label": "5", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "hash": "5738acd3b4d2585b1f155b0ae349489ab3786925691f342654e2b01b64723697", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "5 \n \n  \n        Ent\u00e3o, para que as organiza\u00e7\u00f5es est\u00e3o usando grandes modelos de linguagem? Aqui est\u00e3o apenas alguns exemplos de casos de uso comuns para grandes modelos de linguagem:   CHATBOTS E ASSISTENTES VIRTUAIS Uma das implementa\u00e7\u00f5es mais comuns, os LLMs podem ser usados por organiza\u00e7\u00f5es para fornecer ajuda em tarefas como suporte ao cliente, solu\u00e7\u00e3o de problemas ou at\u00e9 mesmo para ter conversas abertas com prompts fornecidos pelo usu\u00e1rio.   GERA\u00c7\u00c3O DE C\u00d3DIGO E DEPURA\u00c7\u00c3O  Os LLMs podem ser treinados com grandes volumes de exemplos de c\u00f3digo e fornecer trechos \u00fateis de c\u00f3digo como resposta a solicita\u00e7\u00f5es escritas em linguagem natural. Com as t\u00e9cnicas apropriadas, os LLMs tamb\u00e9m podem ser desenvolvidos de forma a fazer refer\u00eancia a outros dados relevantes que talvez n\u00e3o tenham sido treinados, como a documenta\u00e7\u00e3o de uma empresa, para fornecer respostas mais precisas.   AN\u00c1LISE DE SENTIMENTO  Frequentemente, uma tarefa dif\u00edcil de quantificar, os LLMs podem ajudar a analisar emo\u00e7\u00f5es e opini\u00f5es a partir de um texto. Isso pode ajudar as organiza\u00e7\u00f5es a coletarem os dados e o feedback necess\u00e1rios para melhorar a satisfa\u00e7\u00e3o dos clientes.   CLASSIFICA\u00c7\u00c3O E AGRUPAMENTO DE TEXTO  A capacidade de categorizar e classificar grandes volumes de dados permite a identifica\u00e7\u00e3o de temas e tend\u00eancias comuns, apoiando a tomada de decis\u00f5es informadas e estrat\u00e9gias mais direcionadas. \nTRADU\u00c7\u00c3O DE IDIOMAS  Globalize todo o seu conte\u00fado sem horas de trabalho \u00e1rduo simplesmente alimentando suas p\u00e1ginas da web por meio dos LLMs apropriados e traduzindo-os para diferentes idiomas. \u00c0 medida que mais LLMs s\u00e3o treinados em outros idiomas, a qualidade e a disponibilidade continuar\u00e3o melhorando.  RESUMO E PARAFRASEAMENTO  Chamadas ou reuni\u00f5es de clientes completas podem ser resumidas de forma eficiente para que outras pessoas possam digerir o conte\u00fado mais facilmente. Os LLMs podem pegar grandes volumes de texto e resumir apenas os bytes mais importantes.  GERA\u00c7\u00c3O DE CONTE\u00daDO  Comece com um prompt detalhado e deixe um LLM desenvolver um esbo\u00e7o para voc\u00ea. Em seguida, continue com esses prompts e os LLMs podem gerar um primeiro rascunho para voc\u00ea desenvolver. Use-os para criar ideias e fa\u00e7a perguntas ao LLM para ajudar a se inspirar. Observa\u00e7\u00e3o: a maioria dos LLMs n\u00e3o \u00e9 treinada para ser uma m\u00e1quina de fatos. Eles sabem como usar a linguagem, mas podem n\u00e3o saber quem ganhou o grande evento esportivo do ano passado. \u00c9 sempre importante verificar os fatos e entender as respostas antes de us\u00e1-las como refer\u00eancia.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2522, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c9ee7006-4e42-44be-9de3-b24037382828": {"__data__": {"id_": "c9ee7006-4e42-44be-9de3-b24037382828", "embedding": null, "metadata": {"page_label": "6", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "57bce444-d5c7-4bc0-99eb-484872105194", "node_type": "4", "metadata": {"page_label": "6", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "hash": "98c4f8f192ce033287b40a69b621f31fc784c8cf434494d111440c2ff31340ae", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "6 \n \n  \n      PARTE 3 \nAplica\u00e7\u00e3o de grandes modelos de linguagem     Existem alguns caminhos que voc\u00ea pode seguir ao procurar aplicar grandes modelos de linguagem para seu caso de uso espec\u00edfico. Em termos gerais, voc\u00ea pode dividi-los em duas categorias, mas h\u00e1 alguma sobreposi\u00e7\u00e3o entre elas. Vamos abordar brevemente as vantagens e desvantagens de cada uma e em quais cen\u00e1rios cada uma se encaixa melhor.   Servi\u00e7os propriet\u00e1rios Como o primeiro servi\u00e7o amplamente dispon\u00edvel alimentado por LLM, o ChatGPT da OpenAI foi o catalisador explosivo que trouxe os LLMs para o mainstream. O ChatGPT fornece uma interface de usu\u00e1rio (ou API) em que os usu\u00e1rios podem enviar prompts para muitos modelos (GPT-3.5, GPT-4 e outros) e geralmente obter uma resposta r\u00e1pida. Eles est\u00e3o entre os modelos de maior desempenho, treinados em conjuntos de dados enormes, e s\u00e3o capazes de realizar tarefas extremamente complexas tanto do ponto de vista t\u00e9cnico, como gera\u00e7\u00e3o de c\u00f3digo, quanto do ponto de vista criativo, como escrever poesia em um estilo espec\u00edfico. A desvantagem desses servi\u00e7os \u00e9 a quantidade absolutamente enorme de recursos computacionais necess\u00e1rios n\u00e3o apenas para trein\u00e1-los (a OpenAI afirmou que o GPT-4 custou mais de US$ 100 milh\u00f5es para desenvolver), mas tamb\u00e9m para fornecer as respostas. Por esse motivo, esses modelos extremamente grandes provavelmente sempre estar\u00e3o sob o controle de organiza\u00e7\u00f5es \ne exigir\u00e3o que voc\u00ea envie seus dados para seus servidores a fim de interagir com seus modelos de linguagem. Isso levanta preocupa\u00e7\u00f5es com privacidade e seguran\u00e7a, e tamb\u00e9m sujeita os usu\u00e1rios a modelos \u201ccaixa preta\u201d, sobre cujos treinamentos e limites eles n\u00e3o t\u00eam controle. Al\u00e9m disso, devido aos recursos computacionais necess\u00e1rios, esses servi\u00e7os n\u00e3o s\u00e3o gratuitos al\u00e9m de um uso muito limitado, ent\u00e3o o custo se torna um fator ao aplic\u00e1-los em grande escala. Resumindo: servi\u00e7os propriet\u00e1rios s\u00e3o \u00f3timos para usar se voc\u00ea tiver tarefas muito complexas, tiver disposi\u00e7\u00e3o para compartilhar seus dados com terceiros e quiser incorrer em custos ao operar em escala significativa.   Modelos de c\u00f3digo aberto A outra op\u00e7\u00e3o para modelos de linguagem \u00e9 recorrer \u00e0 comunidade de c\u00f3digo aberto, onde houve um crescimento igualmente explosivo nos \u00faltimos anos. Comunidades como a Hugging Face re\u00fanem centenas de milhares de modelos de contribuidores que podem ajudar a resolver muitos casos de uso espec\u00edficos, como gera\u00e7\u00e3o de texto, resumo e classifica\u00e7\u00e3o. A comunidade de c\u00f3digo aberto est\u00e1 rapidamente alcan\u00e7ando o desempenho dos modelos propriet\u00e1rios, mas ainda n\u00e3o conseguiu igualar o desempenho de algo como o GPT-4.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2626, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5362e89b-67da-44cb-934b-492123e1e13b": {"__data__": {"id_": "5362e89b-67da-44cb-934b-492123e1e13b", "embedding": null, "metadata": {"page_label": "7", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0babd3ae-713f-47de-ae7a-786346100d64", "node_type": "4", "metadata": {"page_label": "7", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "hash": "fc71f7b2119e4ab5e331ab68cf2c7bf5834c524892c5f3f6ca539b8459cc4e3a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Um guia compacto sobre grandes modelos de linguagem (LLM) 7  \n \n        Atualmente, requer um pouco mais de esfor\u00e7o para pegar um modelo de c\u00f3digo aberto e come\u00e7ar a us\u00e1-lo, mas o progresso est\u00e1 ocorrendo muito rapidamente para torn\u00e1-los mais acess\u00edveis aos usu\u00e1rios. Na Databricks, por exemplo, fizemos melhorias em frameworks de c\u00f3digo aberto como o MLflow para tornar muito f\u00e1cil para algu\u00e9m com um pouco de experi\u00eancia em Python pegar qualquer modelo transformador da Hugging Face e us\u00e1-lo como um objeto Python. Muitas vezes, voc\u00ea pode encontrar um modelo de c\u00f3digo aberto que resolve seu problema espec\u00edfico e que \u00e9 v\u00e1rias ordens de grandeza menor que o ChatGPT, permitindo que voc\u00ea traga o modelo para seu ambiente e hospede-o voc\u00ea mesmo. Isso significa que voc\u00ea pode manter os dados sob seu controle para preocupa\u00e7\u00f5es com privacidade e governan\u00e7a, al\u00e9m de gerenciar seus custos. Outra grande vantagem de usar modelos de c\u00f3digo aberto \u00e9 a capacidade de ajust\u00e1-los aos seus pr\u00f3prios dados. Como voc\u00ea n\u00e3o est\u00e1 lidando com uma caixa preta de um servi\u00e7o propriet\u00e1rio, existem t\u00e9cnicas que permitem pegar modelos de c\u00f3digo aberto e trein\u00e1-los com seus dados espec\u00edficos, melhorando significativamente o desempenho deles em seu dom\u00ednio espec\u00edfico. Acreditamos que o futuro dos modelos de linguagem seguir\u00e1 nessa dire\u00e7\u00e3o, \u00e0 medida que mais organiza\u00e7\u00f5es desejem ter controle total e compreens\u00e3o de seus LLMs. \nConclus\u00e3o e diretrizes gerais Em \u00faltima an\u00e1lise, cada organiza\u00e7\u00e3o ter\u00e1 desafios \u00fanicos a superar, e n\u00e3o existe uma abordagem \u00fanica para os LLMs. \u00c0 medida que o mundo se torna mais orientado a dados, tudo, incluindo os LLMs, depender\u00e1 de uma base s\u00f3lida de dados. Os LLMs s\u00e3o ferramentas incr\u00edveis, mas devem ser usados e implementados sobre essa base s\u00f3lida de dados. A Databricks oferece tanto essa base s\u00f3lida de dados quanto as ferramentas integradas para permitir que voc\u00ea use e ajuste os LLMs no seu dom\u00ednio.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1922, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "05cdea87-9848-4b4d-ab18-edd2ad6adfdf": {"__data__": {"id_": "05cdea87-9848-4b4d-ab18-edd2ad6adfdf", "embedding": null, "metadata": {"page_label": "8", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bee1c6c4-4bd6-4c35-b3cf-a6db500dda1d", "node_type": "4", "metadata": {"page_label": "8", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "hash": "c6769bd8ef6c0a4d9a8797b6dfd1987d778300c57706b180e6d558baec21f5c2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "8  \n \n     PARTE 4 \nE agora, o que fazer se eu quiser come\u00e7ar a usar LLMs?    Isso depende de onde voc\u00ea est\u00e1 em sua jornada. Felizmente, temos algumas op\u00e7\u00f5es para voc\u00ea. Se voc\u00ea deseja se aprofundar um pouco mais nos LLMs, mas ainda n\u00e3o quer fazer isso por conta pr\u00f3pria, pode assistir a uma das apresenta\u00e7\u00f5es sob demanda de um dos desenvolvedores e palestrantes mais talentosos da Databricks sobre esses conceitos em mais detalhes, durante a palestra \u201cCrie seu pr\u00f3prio grande modelo de linguagem como Dolly\u201d. Se voc\u00ea quiser se aprofundar um pouco mais e expandir seus conhecimentos e compreens\u00e3o dos fundamentos dos LLMs, recomendamos conferir nosso curso sobre LLMs. Voc\u00ea aprender\u00e1 como desenvolver aplicativos prontos para produ\u00e7\u00e3o com LLMs e se aprofundar\u00e1 na teoria por tr\u00e1s dos modelos de funda\u00e7\u00e3o. Se suas m\u00e3os j\u00e1 est\u00e3o tremendo de emo\u00e7\u00e3o e voc\u00ea j\u00e1 tem algum conhecimento pr\u00e1tico de Python e Databricks, forneceremos alguns \u00f3timos exemplos com c\u00f3digo de exemplo que podem ajudar voc\u00ea a come\u00e7ar a trabalhar com LLMs imediatamente.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1035, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "925a460b-d374-4cd5-ae76-43b1ca80b57f": {"__data__": {"id_": "925a460b-d374-4cd5-ae76-43b1ca80b57f", "embedding": null, "metadata": {"page_label": "9", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7475057c-b382-43d0-a062-1e7ad258d49a", "node_type": "4", "metadata": {"page_label": "9", "file_name": "LLM.pdf", "file_path": "/home/dgamorim/development/AIagents/LlamaIndex/data/docs/LLM.pdf", "file_type": "application/pdf", "file_size": 1602946, "creation_date": "2025-06-09", "last_modified_date": "2025-06-09"}, "hash": "dc20901fb705650020bb503837780b0bd4d59ccc9eef6ba1c14d66c30b0dbee7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Sobre a Databricks A Databricks \u00e9 a empresa de dados e IA. Mais de 9.000 organiza\u00e7\u00f5es em todo o mundo, incluindo a Comcast, Cond\u00e9 Nast e mais de 50% da Fortune 500, contam com a Plataforma Databricks Lakehouse para unificar seus dados, an\u00e1lises e IA. A Databricks tem sede em S\u00e3o Francisco, com escrit\u00f3rios em todo o mundo. Fundada pelos criadores originais do Apache Spark\u2122, Delta Lake e MLflow, a Databricks tem como miss\u00e3o ajudar as equipes de dados a resolver os problemas mais dif\u00edceis do mundo. Para saber mais, siga a Databricks no Twitter, LinkedIn e Facebook.                 EXPERIMENTE GR\u00c1TIS    Entre em contato conosco para ver uma demonstra\u00e7\u00e3o: databricks.com/contact                     \u00a9 Databricks 2023. Todos os direitos reservados. Apache, Apache Spark, Spark e o logotipo Spark s\u00e3o marcas registradas da Apache Software Foundation. Pol\u00edtica de privacidade | Termos de uso", "mimetype": "text/plain", "start_char_idx": 5, "end_char_idx": 896, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}}