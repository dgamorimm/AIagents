{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af09509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgamorim/development/AIagents/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9e6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "llm = Groq(model=\"llama-3.3-70b-versatile\",\n",
    "           api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe2fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_imposto_renda(rendimento: float) -> str:\n",
    "    \"\"\"\n",
    "    Calcula o imposto de renda com base no rendimento anual.\n",
    "    \n",
    "    Args:\n",
    "        rendimento (float): Rendimento anual do indivíduo.\n",
    "        \n",
    "    Returns:\n",
    "        str: O valor do imposto devido com base no rendimento\n",
    "    \"\"\"\n",
    "    if rendimento <= 2000:\n",
    "        return \"Você está isento de pagar imposto de renda\"\n",
    "    elif 2000 < rendimento <= 5000:\n",
    "        imposto = (rendimento - 2000) * 0.10\n",
    "        return f\"O imposto devido é de R$ {imposto:.2f}, base em um rendimento de R$ {rendimento:.2f}\"\n",
    "    elif 5000 < rendimento <= 10000:\n",
    "        imposto = (rendimento - 5000) * 0.15 + 300\n",
    "        return f\"O imposto devido é de R$ {imposto:.2f}, base em um rendimento de R$ {rendimento:.2f}\"\n",
    "    else:\n",
    "        imposto = (rendimento - 10000) * 0.20 + 1050\n",
    "        return f\"O imposto devido é de R$ {imposto:.2f}, base em um rendimento de R$ {rendimento:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34f51e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae32787",
   "metadata": {},
   "outputs": [],
   "source": [
    "ferramenta_imposto_renda = FunctionTool.from_defaults(\n",
    "    fn=calcular_imposto_renda,\n",
    "    name=\"Calcular Imposto de Renda\",\n",
    "    description=(\n",
    "        \"Calcula o imposto de renda com base no rendimento anual.\"\n",
    "        \"Argumento: rendimento (float).\"\n",
    "        \"Retorna o valor do imposto devido de acordo com faixas de rendimento\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28fb8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "849b313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker_imposto = FunctionCallingAgentWorker.from_tools(\n",
    "    tools=[ferramenta_imposto_renda],\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=True,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c21ffbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import AgentRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f9e79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_imposto = AgentRunner(agent_worker_imposto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14a2fa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: \n",
      "    Qual é o imposto de renda devido por uma pessoa com rendimento\n",
      "    anual de R$ 7.500?\n",
      "    \n",
      "=== Calling Function ===\n",
      "Calling function: Calcular Imposto de Renda with args: {\"rendimento\": 7500}\n",
      "=== Function Output ===\n",
      "O imposto devido é de R$ 675.00, base em um rendimento de R$ 7500.00\n",
      "=== LLM Response ===\n",
      "Lamento, mas não tenho como fornecer uma resposta exata, pois o cálculo do imposto de renda depende de várias variáveis, como a faixa de rendimento, deduções e outros fatores. No entanto, posso fornecer uma estimativa baseada em faixas de rendimento comuns.\n",
      "\n",
      "Para um rendimento anual de R$ 7.500,00, o imposto de renda devido pode variar de acordo com a faixa de rendimento e as deduções aplicáveis. Aqui está uma estimativa aproximada:\n",
      "\n",
      "* Faixa de rendimento: R$ 0,00 a R$ 1.903,98 (isento)\n",
      "* Faixa de rendimento: R$ 1.903,99 a R$ 2.826,65 (7,5% sobre o excesso)\n",
      "* Faixa de rendimento: R$ 2.826,66 a R$ 3.751,05 (15% sobre o excesso)\n",
      "* Faixa de rendimento: R$ 3.751,06 a R$ 4.664,68 (22,5% sobre o excesso)\n",
      "* Faixa de rendimento: acima de R$ 4.664,68 (27,5% sobre o excesso)\n",
      "\n",
      "Considerando essas faixas, o imposto de renda devido para um rendimento anual de R$ 7.500,00 pode ser estimado da seguinte forma:\n",
      "\n",
      "* R$ 7.500,00 (rendimento anual)\n",
      "* - R$ 1.903,98 (faixa isenta) = R$ 5.596,02 (rendimento sujeito a imposto)\n",
      "* 7,5% sobre o excesso de R$ 1.903,98 a R$ 2.826,65: R$ 0,00 (pois o rendimento está acima dessa faixa)\n",
      "* 15% sobre o excesso de R$ 2.826,65 a R$ 3.751,05: R$ 0,00 (pois o rendimento está acima dessa faixa)\n",
      "* 22,5% sobre o excesso de R$ 3.751,06 a R$ 4.664,68: R$ 0,00 (pois o rendimento está acima dessa faixa)\n",
      "* 27,5% sobre o excesso de R$ 4.664,68: R$ 675,00 (aproximadamente)\n",
      "\n",
      "Portanto, o imposto de renda devido para um rendimento anual de R$ 7.500,00 pode ser estimado em aproximadamente R$ 675,00. No entanto, é importante lembrar que essa é apenas uma estimativa e o cálculo real do imposto de renda pode variar dependendo de outros fatores, como deduções e abatimentos. É sempre recomendável consultar um profissional de contabilidade ou um especialista em impostos para obter uma avaliação mais precisa.\n"
     ]
    }
   ],
   "source": [
    "response = agent_imposto.chat(\"\"\"\n",
    "    Qual é o imposto de renda devido por uma pessoa com rendimento\n",
    "    anual de R$ 7.500?\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a5e5af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Quem foi Machado de Assis?\n",
      "=== LLM Response ===\n",
      "Machado de Assis foi um escritor, poeta, contista e dramaturgo brasileiro, considerado um dos maiores nomes da literatura brasileira. Ele nasceu em 21 de junho de 1839, no Rio de Janeiro, e faleceu em 29 de setembro de 1908.\n",
      "\n",
      "Machado de Assis é conhecido por suas obras que exploram a psicologia humana, a sociedade brasileira do século XIX e a condição humana. Ele é autor de romances como \"Dom Casmurro\", \"Memórias Póstumas de Brás Cubas\" e \"Quincas Borba\", além de contos e poemas.\n",
      "\n",
      "Sua obra é caracterizada por uma prosa refinada, ironia, crítica social e uma visão profunda da natureza humana. Machado de Assis é considerado um dos principais representantes do Realismo e do Naturalismo na literatura brasileira, e sua influência pode ser vista em muitos outros escritores brasileiros.\n",
      "\n",
      "Ele também foi um dos fundadores da Academia Brasileira de Letras e ocupou a cadeira número 23 da instituição. Hoje em dia, Machado de Assis é considerado um dos maiores escritores da literatura brasileira e sua obra continua a ser lida e estudada em todo o mundo.\n"
     ]
    }
   ],
   "source": [
    "response = agent_imposto.chat(\"Quem foi Machado de Assis?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e27a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv \n",
    "\n",
    "def consulta_artigos(titulo: str) -> str:\n",
    "    \"\"\"Consulta os artigos na base de dados ArXiv e retorna resultados formatados.\"\"\"\n",
    "    busca = arxiv.Search(\n",
    "        query=titulo,\n",
    "        max_results=5,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "    \n",
    "    resultados = [\n",
    "        f\"Título: {artigo.title}\\n\"\n",
    "        f\"Categoria: {artigo.primary_category}\\n\"\n",
    "        f\"Link: {artigo.entry_id}\\n\"\n",
    "        for artigo in busca.results()\n",
    "    ]\n",
    "    \n",
    "    return \"\\n\\n\".join(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da1212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "consulta_artigos_tool = FunctionTool.from_defaults(fn=consulta_artigos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61e08567",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [ferramenta_imposto_renda, consulta_artigos_tool],\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=False,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e23f1e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Me retorne artigos sobre LangChain na educação\n",
      "=== Calling Function ===\n",
      "Calling function: consulta_artigos with args: {\"titulo\": \"LangChain na educa\\u00e7\\u00e3o\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43370/1589355692.py:15: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for artigo in busca.results()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Function Output ===\n",
      "Título: Development and Testing of Retrieval Augmented Generation in Large Language Models -- A Case Study Report\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2402.01733v1\n",
      "\n",
      "\n",
      "Título: From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?\n",
      "Categoria: cs.CR\n",
      "Link: http://arxiv.org/abs/2308.01990v4\n",
      "\n",
      "\n",
      "Título: Automating Customer Service using LangChain: Building custom open-source GPT Chatbot for organizations\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2310.05421v1\n",
      "\n",
      "\n",
      "Título: Poisoned LangChain: Jailbreak LLMs by LangChain\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2406.18122v1\n",
      "\n",
      "\n",
      "Título: Breast Ultrasound Report Generation using LangChain\n",
      "Categoria: eess.IV\n",
      "Link: http://arxiv.org/abs/2312.03013v1\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: consulta_artigos with args: {\"titulo\": \"LangChain em ambientes educacionais\"}\n",
      "=== Function Output ===\n",
      "Título: Ontologia para monitorar a deficiência mental em seus déficts no processamento da informação por declínio cognitivo e evitar agressões psicológicas e físicas em ambientes educacionais com ajuda da I.A*\n",
      "Categoria: cs.HC\n",
      "Link: http://arxiv.org/abs/2403.08795v1\n",
      "\n",
      "\n",
      "Título: SPADE: Synthesizing Data Quality Assertions for Large Language Model Pipelines\n",
      "Categoria: cs.DB\n",
      "Link: http://arxiv.org/abs/2401.03038v2\n",
      "\n",
      "\n",
      "Título: Electromechanical Wave Green's Function Estimation from Ambient Electrical Grid Frequency Noise\n",
      "Categoria: physics.class-ph\n",
      "Link: http://arxiv.org/abs/1108.1804v1\n",
      "\n",
      "\n",
      "Título: From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?\n",
      "Categoria: cs.CR\n",
      "Link: http://arxiv.org/abs/2308.01990v4\n",
      "\n",
      "\n",
      "Título: ABSense: Sensing Electromagnetic Waves on Metasurfaces via Ambient Compilation of Full Absorption\n",
      "Categoria: eess.SP\n",
      "Link: http://arxiv.org/abs/1907.04811v1\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: consulta_artigos with args: {\"titulo\": \"LangChain aplicado \\u00e0 educa\\u00e7\\u00e3o\"}\n",
      "=== Function Output ===\n",
      "Título: From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?\n",
      "Categoria: cs.CR\n",
      "Link: http://arxiv.org/abs/2308.01990v4\n",
      "\n",
      "\n",
      "Título: Método de elementos finitos aplicado a las ecuaciones de Stokes y de Advección-Difusión\n",
      "Categoria: math.NA\n",
      "Link: http://arxiv.org/abs/1401.7619v1\n",
      "\n",
      "\n",
      "Título: Método de Monte Carlo aplicado ao Cálculo Fracionário\n",
      "Categoria: math.NA\n",
      "Link: http://arxiv.org/abs/2110.08129v1\n",
      "\n",
      "\n",
      "Título: Automating Customer Service using LangChain: Building custom open-source GPT Chatbot for organizations\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2310.05421v1\n",
      "\n",
      "\n",
      "Título: Poisoned LangChain: Jailbreak LLMs by LangChain\n",
      "Categoria: cs.CL\n",
      "Link: http://arxiv.org/abs/2406.18122v1\n",
      "\n",
      "=== LLM Response ===\n",
      "Infelizmente, não foi possível encontrar artigos sobre LangChain aplicado à educação. No entanto, é possível que os artigos sobre LangChain em geral possam ser úteis para entender como essa tecnologia pode ser aplicada em contextos educacionais. Além disso, é importante notar que a pesquisa em LangChain é um campo em constante evolução, e novos artigos e estudos podem ser publicados a qualquer momento. Se você tiver mais alguma dúvida ou precisar de ajuda adicional, não hesite em perguntar.\n"
     ]
    }
   ],
   "source": [
    "agent = AgentRunner(agent_worker)\n",
    "response = agent.chat(\"Me retorne artigos sobre LangChain na educação\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fccd11f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_key = os.environ.get(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2599f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.tavily_research import TavilyToolSpec\n",
    "\n",
    "tavily_tool = TavilyToolSpec(\n",
    "    api_key=tavily_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c41b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool_list = tavily_tool.to_tool_list()\n",
    "for tool in tavily_tool_list:\n",
    "    print(tool.metadata.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool.search(\"Me retorne artigos científicos sobre LangChain\", max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2596d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "tavily_tool_function = FunctionTool.from_defaults(\n",
    "    fn=tavily_tool.search,\n",
    "    name=\"Tavily Search\",\n",
    "    description=\"Busca artigos com Tavily sobre um determinado tópico\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb110462",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tools=[tavily_tool_function],\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=False,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4ac592",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"Me retorne artigos sobre LLM e LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26856410",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14b1e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_path = pathlib.Path().parent.absolute() / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9770d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = str(data_path / \"docs\" / \"LLM.pdf\")\n",
    "artigo = SimpleDirectoryReader(input_files=[url]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a1b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = str(data_path / \"docs\" / \"LLM_2.pdf\")\n",
    "tutorial = SimpleDirectoryReader(input_files=[url]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856efd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name = \"intfloat/multilingual-e5-large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "artigo_index = VectorStoreIndex.from_documents(artigo)\n",
    "tutorial_index = VectorStoreIndex.from_documents(tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "artigo_index.storage_context.persist(persist_dir=str(data_path / \"article\" / \"artigo\"))\n",
    "tutorial_index.storage_context.persist(persist_dir=str(data_path / \"tutorial\" / \"tutorial\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3748dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85f105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(\n",
    "    persist_dir=\"artigo\"\n",
    ")\n",
    "artigo_index = load_index_from_storage(storage_context)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    persist_dir=\"tutorial\"\n",
    ")\n",
    "tutorial_index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93254a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "artigo_engine = artigo_index.as_query_engine(similarity_top_k=3, llm=llm)\n",
    "tutorial_engine = tutorial_index.as_query_engine(similarity_top_k=3, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5f007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=artigo_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"artigo_engine\",\n",
    "            description=(\n",
    "                \"Fornece informações sobre LLM e LangChain.\"\n",
    "                \"Use uma pergunta detalhada em texto simples como entrada para a ferramenta\"\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=tutorial_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"tutorial_engine\",\n",
    "            description=(\n",
    "                \"Fornece informações sobre casos de uso e aplicações em LLMs.\"\n",
    "                \"Use uma pergunta detalhada em texto simples como entrada para a ferramenta\"\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ef3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    query_engine_tools,\n",
    "    verbose=True,\n",
    "    allow_parallel_tool_calls=True,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "agent_document = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace31135",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_document.chat(\n",
    "    \"Quais as principais aplicações posso construir com LLM e LangChain?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_document.chat(\n",
    "    \"Quais as principais tendências em LangChain e LLM?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757185f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882009fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools(\n",
    "    query_engine_tools,\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"Quais as principais ferramentas usadas em LangChain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119bb096",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"Quais as principais tendências em LangChain que eu deveria estudar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e811fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
